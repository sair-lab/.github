[<img src="https://github.com/sair-lab/.github/assets/8695500/2308d56a-70f5-480f-936d-379c1a744957" height="100"/>](https://sairlab.org)

## ğŸ™‹â€â™€ï¸ Welcome to SAIR Lab ğŸ™Œ
 
- At the intersection of **perception**, **spatial reasoning**, and **decision-making**, we are committed to advancing mobile robots toward **human-level autonomy** by developing **algorithms and systems** that can **efficiently** and **robustly**:

  - Perceive and interpret various sensory inputs such as images, point clouds, and proprioceptive data.
  - Integrate neural and symbolic memory representations to capture spatial common sense and semantic knowledge.
  - Reason, plan, and act in real time to navigate, interact, and adapt within unstructured and dynamic environments.

## About open-source.

- SAIR Lab is leading [PyPose](https://github.com/pypose/pypose), an open-source Python library for **differentiable robotics on manifolds**.
- This GitHub organization provides source code for **research** and **publications**.
- Teaching materials are available at GitHub organization [sairclass](https://github.com/sairclass).

## Find us elsewhere ğŸŒ

[![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/company/sairlab)](https://www.linkedin.com/company/sairlab)
[![Twitter Badge](https://img.shields.io/badge/-Twitter-1ca0f1?style=flat&labelColor=1ca0f1&logo=twitter&logoColor=white&link=https://twitter.com/sairlab_org/)](https://twitter.com/sairlab_org/)
[![YouTube Badge](https://img.shields.io/badge/-YouTube-1ca0f1?style=flat&labelColor=1ca0f1&logo=youtube&logoColor=white&link=https://www.youtube.com/@sairlab/videos)](https://www.youtube.com/@sairlab/videos)
